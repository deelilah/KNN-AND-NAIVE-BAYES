# Project on Knn and Naive bayes classifiers.
# KNN

K Nearest Neighbor(KNN) is a very simple, easy to understand, versatile and one of the topmost machine learning algorithms. KNN used in the variety of applications such as finance, healthcare, political science, handwriting detection, image recognition and video recognition. In Credit ratings, financial institutes will predict the credit rating of customers. In loan disbursement, banking institutes will predict whether the loan is safe or risky. In political science, classifying potential voters in two classes will vote or won’t vote. KNN algorithm used for both classification and regression problems. KNN algorithm based on feature similarity approach.
# Naive Bayes

# 1.0 TITANIC DATASET

# Problem Statement

  This week's project requires us to implement a K-nearest neighbor (kNN) classifier and a Naive Bayes classifier. Once we conduct the experiments, we will calculate the resulting metrics.
what sorts of people were more likely to survive?” using passenger data (ie name, age, gender, socio-economic class, etc)

# 1.1 Metric of Success

Randomly partition each dataset into two parts i.e 80 - 20 sets.
For dataset 1, because we don't have the label for the test set, we will use the train set to create train and test data (i.e. splitting further), then perform K-nearest neighbor classification.
For dataset 2, perform classification of the testing set samples using the Naive Bayes Classifier.
Compute the accuracy (percentage of correct classification).
Report the confusion matrix of each classifier.
Repeat step 2 to step 4 twice, each time splitting the datasets differently i.e. 70-30, 60-40, then note the outcomes of your modeling.
Suggest and apply at least one of the optimization techniques that you learned earlier this week.
Provide further recommendations to improve both classifiers.
VERIFY WITH ACCURACY AND CONFUSION MATRIX

# 1.2 Understand the Context
We will try to do is from the first data that we have for the titanic,we have train data and test data.IN step three,we have been asked to split the train data into 80:20 as the test has no labels and perform the knn
