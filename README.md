# KNN-AND-NAIVE-BAYES
1.0 TITANIC DATASET
Problem Statement
This week's project requires us to implement a K-nearest neighbor (kNN) classifier and a Naive Bayes classifier. Once we conduct the experiments, we will calculate the resulting metrics.

what sorts of people were more likely to survive?‚Äù using passenger data (ie name, age, gender, socio-economic class, etc)

1.1 Metric of Success
Randomly partition each dataset into two parts i.e 80 - 20 sets.

For dataset 1, because we don't have the label for the test set, we will use the train set to create train and test data (i.e. splitting further), then perform K-nearest neighbor classification.

For dataset 2, perform classification of the testing set samples using the Naive Bayes Classifier.

Compute the accuracy (percentage of correct classification).

Report the confusion matrix of each classifier.

Repeat step 2 to step 4 twice, each time splitting the datasets differently i.e. 70-30, 60-40, then note the outcomes of your modeling.

Suggest and apply at least one of the optimization techniques that you learned earlier this week.

Provide further recommendations to improve both classifiers.

VERIFY WITH ACCURACY AND CONFUSION MATRIX

1.2 Understand the Context
We will try to do is from the first data that we have for the titanic,we have train data and test data.IN step three,we have been asked to split the train data into 80:20 as the test has no labels and perform the knn
